{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66269362",
   "metadata": {},
   "source": [
    "# Polars with polars-st Spatial Analysis and Iceberg Integration\n",
    "\n",
    "This notebook demonstrates how to use Polars with polars-st for high-performance geospatial processing and Apache Iceberg for data lakehouse capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939579ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import sys\n",
    "sys.path.append('/opt/workspace/config')\n",
    "\n",
    "import polars as pl\n",
    "import polars_st as st\n",
    "import geopandas as gpd\n",
    "import folium\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# Import our configuration\n",
    "from iceberg_spatial_config import (\n",
    "    setup_polars_spatial,\n",
    "    create_polars_config,\n",
    "    create_spatial_iceberg_table_example,\n",
    "    spatial_query_example,\n",
    "    advanced_spatial_operations,\n",
    "    create_iceberg_catalog\n",
    ")\n",
    "\n",
    "print(f\"Polars version: {pl.__version__}\")\n",
    "print(f\"Polars-st imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d6ea91",
   "metadata": {},
   "source": [
    "## Setup Polars Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f7be6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure Polars for optimal performance\n",
    "setup_polars_spatial()\n",
    "config = create_polars_config()\n",
    "print(\"Polars configuration:\", config)\n",
    "\n",
    "# Set up Iceberg catalog\n",
    "try:\n",
    "    catalog = create_iceberg_catalog()\n",
    "    print(\"Iceberg catalog created successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"Iceberg catalog setup (optional): {e}\")\n",
    "    catalog = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0a1755",
   "metadata": {},
   "source": [
    "## Create Sample Spatial Data with Polars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6769c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample spatial data\n",
    "df = create_spatial_iceberg_table_example(catalog, \"sample_locations\")\n",
    "print(f\"Created DataFrame with {len(df)} rows\")\n",
    "print(\"\\nDataFrame info:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879de5d5",
   "metadata": {},
   "source": [
    "## Basic Spatial Operations with polars-st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda64658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show spatial operations\n",
    "result = spatial_query_example(df)\n",
    "print(\"Spatial query results:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ec5aae",
   "metadata": {},
   "source": [
    "## Advanced Spatial Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf7849f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform advanced spatial operations\n",
    "advanced_result = advanced_spatial_operations(df)\n",
    "print(\"Advanced spatial analysis results:\")\n",
    "print(advanced_result.select([\"name\", \"buffer_area\", \"within_convex_hull\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ecaf53",
   "metadata": {},
   "source": [
    "## Working with Larger Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac0005c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a larger synthetic dataset for performance demonstration\n",
    "np.random.seed(42)\n",
    "n_points = 10000\n",
    "\n",
    "large_df = pl.DataFrame({\n",
    "    \"id\": range(n_points),\n",
    "    \"longitude\": np.random.uniform(-180, 180, n_points),\n",
    "    \"latitude\": np.random.uniform(-90, 90, n_points),\n",
    "    \"value\": np.random.uniform(0, 100, n_points),\n",
    "    \"category\": np.random.choice(['A', 'B', 'C'], n_points)\n",
    "})\n",
    "\n",
    "# Add spatial geometry column\n",
    "large_df = large_df.with_columns([\n",
    "    st.from_xy(\"longitude\", \"latitude\").alias(\"geometry\")\n",
    "])\n",
    "\n",
    "print(f\"Created large dataset with {len(large_df):,} points\")\n",
    "print(\"First few rows:\")\n",
    "print(large_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c36e6e",
   "metadata": {},
   "source": [
    "## Spatial Filtering and Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e2b42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a bounding box for filtering (roughly covering Europe)\n",
    "bbox_west, bbox_south = -10.0, 35.0\n",
    "bbox_east, bbox_north = 40.0, 70.0\n",
    "\n",
    "# Filter points within bounding box\n",
    "europe_points = large_df.filter(\n",
    "    (pl.col(\"longitude\") >= bbox_west) & \n",
    "    (pl.col(\"longitude\") <= bbox_east) &\n",
    "    (pl.col(\"latitude\") >= bbox_south) & \n",
    "    (pl.col(\"latitude\") <= bbox_north)\n",
    ")\n",
    "\n",
    "print(f\"Points in Europe bounding box: {len(europe_points):,}\")\n",
    "\n",
    "# Aggregate by category\n",
    "category_stats = europe_points.group_by(\"category\").agg([\n",
    "    pl.count().alias(\"count\"),\n",
    "    pl.col(\"value\").mean().alias(\"avg_value\"),\n",
    "    pl.col(\"longitude\").mean().alias(\"center_lon\"),\n",
    "    pl.col(\"latitude\").mean().alias(\"center_lat\")\n",
    "])\n",
    "\n",
    "print(\"\\nCategory statistics:\")\n",
    "print(category_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8549de46",
   "metadata": {},
   "source": [
    "## Spatial Joins with polars-st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6289a6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create some reference polygons (simplified regions)\n",
    "regions_df = pl.DataFrame({\n",
    "    \"region_id\": [1, 2, 3],\n",
    "    \"region_name\": [\"Region A\", \"Region B\", \"Region C\"],\n",
    "    \"center_lon\": [0.0, 10.0, 20.0],\n",
    "    \"center_lat\": [50.0, 55.0, 45.0],\n",
    "    \"radius\": [5.0, 7.0, 6.0]  # degrees\n",
    "})\n",
    "\n",
    "# Create circular polygons for regions (approximate)\n",
    "regions_df = regions_df.with_columns([\n",
    "    st.buffer(\n",
    "        st.from_xy(\"center_lon\", \"center_lat\"), \n",
    "        pl.col(\"radius\")\n",
    "    ).alias(\"region_polygon\")\n",
    "])\n",
    "\n",
    "print(\"Regions created:\")\n",
    "print(regions_df.select([\"region_id\", \"region_name\", \"center_lon\", \"center_lat\", \"radius\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46c7922",
   "metadata": {},
   "source": [
    "## Performance Comparison: Lazy vs Eager Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071f6674",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Eager evaluation\n",
    "start_time = time.time()\n",
    "eager_result = large_df.filter(\n",
    "    pl.col(\"value\") > 50\n",
    ").with_columns([\n",
    "    st.buffer(pl.col(\"geometry\"), 0.1).alias(\"buffered_geom\")\n",
    "])\n",
    "eager_time = time.time() - start_time\n",
    "\n",
    "print(f\"Eager evaluation time: {eager_time:.3f} seconds\")\n",
    "print(f\"Result shape: {eager_result.shape}\")\n",
    "\n",
    "# Lazy evaluation\n",
    "start_time = time.time()\n",
    "lazy_result = large_df.lazy().filter(\n",
    "    pl.col(\"value\") > 50\n",
    ").with_columns([\n",
    "    st.buffer(pl.col(\"geometry\"), 0.1).alias(\"buffered_geom\")\n",
    "])\n",
    "# Only collect when needed\n",
    "lazy_collected = lazy_result.collect()\n",
    "lazy_time = time.time() - start_time\n",
    "\n",
    "print(f\"Lazy evaluation time: {lazy_time:.3f} seconds\")\n",
    "print(f\"Result shape: {lazy_collected.shape}\")\n",
    "print(f\"Performance improvement: {(eager_time/lazy_time - 1)*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d823ef0",
   "metadata": {},
   "source": [
    "## Visualization with Folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ad951f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert a subset of data for visualization\n",
    "viz_data = europe_points.filter(\n",
    "    pl.col(\"value\") > 75  # Only high-value points\n",
    ").head(100)  # Limit for performance\n",
    "\n",
    "# Extract coordinates for folium\n",
    "coords_data = viz_data.with_columns([\n",
    "    st.x(pl.col(\"geometry\")).alias(\"lon\"),\n",
    "    st.y(pl.col(\"geometry\")).alias(\"lat\")\n",
    "]).select([\"lon\", \"lat\", \"value\", \"category\"]).to_pandas()\n",
    "\n",
    "# Create interactive map\n",
    "center_lat = coords_data['lat'].mean()\n",
    "center_lon = coords_data['lon'].mean()\n",
    "\n",
    "m = folium.Map(location=[center_lat, center_lon], zoom_start=4)\n",
    "\n",
    "# Color mapping for categories\n",
    "colors = {'A': 'red', 'B': 'blue', 'C': 'green'}\n",
    "\n",
    "# Add points to map\n",
    "for idx, row in coords_data.iterrows():\n",
    "    folium.CircleMarker(\n",
    "        location=[row['lat'], row['lon']],\n",
    "        radius=max(3, row['value'] / 10),  # Size based on value\n",
    "        popup=f\"Category: {row['category']}<br>Value: {row['value']:.2f}\",\n",
    "        color=colors.get(row['category'], 'gray'),\n",
    "        fill=True,\n",
    "        opacity=0.7\n",
    "    ).add_to(m)\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9ad7fc",
   "metadata": {},
   "source": [
    "## Data Export and Persistence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfda5318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory\n",
    "output_dir = Path(\"/opt/workspace/data/output\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Export to various formats\n",
    "\n",
    "# 1. Parquet (efficient for large datasets)\n",
    "parquet_path = output_dir / \"spatial_data.parquet\"\n",
    "europe_points.write_parquet(parquet_path, compression=\"snappy\")\n",
    "print(f\"Exported {len(europe_points)} rows to {parquet_path}\")\n",
    "\n",
    "# 2. CSV for interoperability\n",
    "csv_data = europe_points.with_columns([\n",
    "    st.to_wkt(pl.col(\"geometry\")).alias(\"geometry_wkt\")\n",
    "]).drop(\"geometry\")\n",
    "\n",
    "csv_path = output_dir / \"spatial_data.csv\"\n",
    "csv_data.write_csv(csv_path)\n",
    "print(f\"Exported to CSV: {csv_path}\")\n",
    "\n",
    "# 3. GeoJSON via GeoPandas conversion\n",
    "pandas_df = europe_points.with_columns([\n",
    "    st.to_wkt(pl.col(\"geometry\")).alias(\"geometry_wkt\")\n",
    "]).to_pandas()\n",
    "\n",
    "# Convert to GeoDataFrame\n",
    "from shapely import wkt\n",
    "pandas_df['geometry'] = pandas_df['geometry_wkt'].apply(wkt.loads)\n",
    "gdf = gpd.GeoDataFrame(pandas_df.drop(['geometry_wkt'], axis=1), geometry='geometry')\n",
    "\n",
    "geojson_path = output_dir / \"spatial_data.geojson\"\n",
    "gdf.to_file(geojson_path, driver='GeoJSON')\n",
    "print(f\"Exported to GeoJSON: {geojson_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3f59c3",
   "metadata": {},
   "source": [
    "## Performance Summary and Best Practices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4cfe37",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Polars + polars-st Performance Summary ===\")\n",
    "print(f\"• Processed {n_points:,} spatial points\")\n",
    "print(f\"• Filtered to {len(europe_points):,} points in Europe\")\n",
    "print(f\"• Created buffer zones and performed spatial operations\")\n",
    "print(f\"• Lazy evaluation provided {(eager_time/lazy_time - 1)*100:.1f}% performance improvement\")\n",
    "print()\n",
    "print(\"=== Best Practices for Polars + polars-st ===\")\n",
    "print(\"1. Use lazy evaluation with .lazy() for complex operations\")\n",
    "print(\"2. Chain spatial operations efficiently\")\n",
    "print(\"3. Filter early to reduce data size\")\n",
    "print(\"4. Use appropriate data types (Float64 for coordinates)\")\n",
    "print(\"5. Leverage Polars' columnar operations for batch processing\")\n",
    "print(\"6. Use Parquet format for persistent storage\")\n",
    "print(\"7. Consider memory usage when working with large geometries\")\n",
    "print()\n",
    "print(\"=== Available Spatial Operations (polars-st) ===\")\n",
    "spatial_ops = [\n",
    "    \"st.point(x, y)\",\n",
    "    \"st.from_xy(x_col, y_col)\", \n",
    "    \"st.from_wkt(wkt_string)\",\n",
    "    \"st.to_wkt(geometry)\",\n",
    "    \"st.distance(geom1, geom2)\",\n",
    "    \"st.buffer(geometry, distance)\",\n",
    "    \"st.area(geometry)\",\n",
    "    \"st.within(geom1, geom2)\",\n",
    "    \"st.contains(geom1, geom2)\",\n",
    "    \"st.intersects(geom1, geom2)\"\n",
    "]\n",
    "for op in spatial_ops:\n",
    "    print(f\"• {op}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b424a73",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e4b6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Analysis completed successfully!\")\n",
    "print(f\"Output files saved to: {output_dir}\")\n",
    "print(\"\\nFiles created:\")\n",
    "for file in output_dir.glob(\"*\"):\n",
    "    print(f\"• {file.name} ({file.stat().st_size / 1024:.1f} KB)\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
